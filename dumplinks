#!/usr/bin/python
# encoding: utf-8

import sys
import getopt
import re
import urllib
import urlparse
import BeautifulSoup
from xml.sax.saxutils import unescape

class DumplinksOpener(urllib.FancyURLopener):
    def __init__(self, user, passwd, agent):
        urllib.FancyURLopener.__init__(self)
        self.user = user
        self.passwd = passwd
        if agent:
            self.version = agent
    def prompt_user_passwd(self, host, realm):
        return self.user, self.passwd

def any(s):
    return True

def dump(url, fp, inspect, pat):
    soup = BeautifulSoup.BeautifulSoup(fp.read())
    attr = {'a': 'href', 'img': 'src'}
    tags = []
    for b in soup.findAll('base', {'href': any}):
        url = b['href']
    for i in inspect:
        for t in soup.findAll(i, {attr[i]: pat}):
            try:
                print urlparse.urljoin(url, unescape(t[attr[t.name]].strip()))
            except:
                pass

if __name__ == '__main__':
    opts, args = getopt.getopt(sys.argv[1:], 'A:a:ilr:')

    agent = None
    user = None
    passwd = None
    inspect = ['a', 'img']
    pat = any

    for opt, arg in opts:
        if opt == '-A':
            agent = arg
        if opt == '-a':
            user, passwd = arg.split(':')
        if opt == '-i':
            inspect = ['img']
        if opt == '-l':
            inspect = ['a']
        if opt == '-r':
            pat = re.compile(arg, re.I|re.M)

    opener = DumplinksOpener(user, passwd, agent)

    if args:
        for url in args:
            dump(url, opener.open(url), inspect, pat)
    else:
        dump('', sys.stdin, inspect, pat)
